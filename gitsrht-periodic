#!/usr/bin/env python3
import math
import random
import sqlalchemy as sa
import subprocess
from srht.config import cfg
from srht.database import DbSession
from gitsrht.repos import GitRepoApi
from gitsrht.types import Repository, RepoVisibility
from datetime import datetime, timedelta

db = DbSession(cfg("git.sr.ht", "connection-string"))
db.init()
repo_api = GitRepoApi()

def cleanup_autocreated():
    due = datetime.utcnow() - timedelta(minutes=20)
    repos = (Repository.query
            .filter(Repository.visibility == RepoVisibility.autocreated)
            .filter(Repository.created < due)).all()
    for r in repos:
      # Use session.delete()+do_delete_repo() instead of d_r(),
      # which commits immediately
      repo_api.do_delete_repo(r)
      db.session.delete(r)
    db.session.commit()

def gc():
    repo_count = Repository.query.count()

    # *srht-periodic scripts are run every twenty minutes,
    # this gives us 504 runs over the course of a week;
    # hence, if we GC a 504th of the repository count each time,
    # on average, we will have GCd every repo around once a week.
    limit = int(math.ceil(repo_count / (7 * 24 * 60 / 20)))

    repos = (Repository.query
            .offset(random.randrange(0, repo_count + 1 - limit))
            .limit(limit)).all()
    for r in repos:
        subprocess.run(["git", "-C", r.path, "gc", "--quiet"],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

cleanup_autocreated()
gc()
